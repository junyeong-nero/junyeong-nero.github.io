<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bilingual Translation LLM | Junyeong Song</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="projects.css">
</head>

<body>
    <a href="../index.html" class="back-btn" data-i18n="nav.back">‚Üê Back to Portfolio</a>
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle dark mode">
        <span class="sun-icon">‚òÄÔ∏è</span>
        <span class="moon-icon">üåô</span>
    </button>
    <button class="lang-toggle" id="langToggle" aria-label="Toggle language">Ìïú</button>

    <main class="container project-detail">
        <div class="project-header">
            <span class="project-icon-large">üó£Ô∏è</span>
            <div class="project-meta">
                <h1>Bilingual Translation LLM</h1>
                <span class="project-date">2024.05 - 2024.06</span>
            </div>
        </div>

        <section class="project-section">
            <h2>üìã Project Overview</h2>
            <p>Developed a bidirectional translation model between Jeju dialect and standard Korean,
                addressing the challenge of preserving endangered regional languages through AI technology.
                The project explored various fine-tuning methodologies including Full fine-tuning, LoRA, and QLoRA
                (4-bit)
                to find the optimal balance between translation quality and computational efficiency.</p>
        </section>

        <section class="project-section">
            <h2>üéØ Problem Definition & Goals</h2>
            <ul class="feature-list">
                <li><strong>Problem:</strong> Jeju dialect is classified as a critically endangered language by UNESCO.
                    Younger generations have difficulty understanding traditional Jeju speech, leading to cultural
                    heritage loss.</li>
                <li><strong>Goal 1:</strong> Build an accurate bidirectional translation system between Jeju dialect and
                    standard Korean.</li>
                <li><strong>Goal 2:</strong> Compare different fine-tuning methods (Full, LoRA, QLoRA) for
                    encoder-decoder translation models.</li>
                <li><strong>Goal 3:</strong> Create reusable datasets and models to support Korean dialect preservation
                    efforts.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2>‚öôÔ∏è Key Features & Contributions</h2>
            <ul class="feature-list">
                <li><strong>Dataset Preparation:</strong> Processed AIhub "Korean Dialect Utterances (Jeju)" dataset,
                    creating parallel corpus suitable for seq2seq training.</li>
                <li><strong>Multi-Model Comparison:</strong> Evaluated both KoT5 and KoBART architectures for
                    translation quality.</li>
                <li><strong>Parameter-Efficient Fine-tuning:</strong> Implemented LoRA and QLoRA (4-bit) to enable
                    training on resource-constrained environments while maintaining quality.</li>
                <li><strong>Comprehensive Evaluation:</strong> Established evaluation pipeline using BLEU and ROUGE
                    scores
                    for systematic comparison of different approaches.</li>
                <li><strong>Public Release:</strong> Published processed dataset on HuggingFace for community use.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2>üîß Technical Challenges & Solutions</h2>
            <ul class="feature-list">
                <li><strong>Low-Resource Language:</strong> Limited training data for Jeju dialect.
                    Applied data augmentation techniques and leveraged transfer learning from standard Korean models.
                </li>
                <li><strong>Dialect Variability:</strong> Jeju dialect has significant regional variations even within
                    the island.
                    Focused on the most common patterns while preserving regional diversity in the dataset.</li>
                <li><strong>Encoder-Decoder Complexity:</strong> Seq2seq models required careful hyperparameter tuning.
                    Used HuggingFace's Seq2SeqTrainer with systematic hyperparameter search.</li>
                <li><strong>Quantization Trade-offs:</strong> 4-bit QLoRA showed some quality degradation.
                    Documented trade-offs between efficiency and quality to guide practical deployment decisions.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2>üìà Results & Learnings</h2>
            <ul class="feature-list">
                <li><strong>Translation Quality:</strong> Achieved competitive BLEU scores demonstrating effective
                    dialect-to-standard translation capability.</li>
                <li><strong>Efficiency Analysis:</strong> LoRA achieved near full fine-tuning quality with 90% fewer
                    trainable parameters.</li>
                <li><strong>Cultural Impact:</strong> Created tools that can help bridge generational language gaps
                    and support Jeju dialect preservation efforts.</li>
                <li><strong>Key Learning:</strong> Gained practical experience in low-resource NLP, parameter-efficient
                    fine-tuning,
                    and the unique challenges of working with endangered language preservation.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2>üõ†Ô∏è Technologies</h2>
            <div class="tech-tags">
                <span class="tech-tag">KoT5</span>
                <span class="tech-tag">KoBART</span>
                <span class="tech-tag">Hugging Face trl</span>
                <span class="tech-tag">LoRA</span>
                <span class="tech-tag">QLoRA</span>
                <span class="tech-tag">Seq2SeqTrainer</span>
            </div>
        </section>

        <section class="project-section">
            <h2>üîó Links</h2>
            <div class="project-links">
                <a href="https://huggingface.co/datasets/junyeong-nero/jeju-dialect-to-standard" target="_blank"
                    class="project-link">
                    ü§ó HuggingFace Dataset
                </a>
            </div>
        </section>
    </main>

    <script src="../theme.js"></script>
    <script src="../lang.js"></script>
</body>

</html>