<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tiny-chatbot-agents | Junyeong Song</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="projects.css">
</head>

<body>
    <a href="../index.html" class="back-btn" data-i18n="nav.back">‚Üê Back to Portfolio</a>
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle dark mode">
        <span class="sun-icon">‚òÄÔ∏è</span>
        <span class="moon-icon">üåô</span>
    </button>
    <button class="lang-toggle" id="langToggle" aria-label="Toggle language">Ìïú</button>

    <main class="container project-detail">
        <div class="project-header">
            <span class="project-icon-large">ü§ñ</span>
            <div class="project-meta">
                <h1>tiny-chatbot-agents</h1>
                <span class="project-date">2025.01 - Present</span>
            </div>
        </div>

        <section class="project-section">
            <h2 data-i18n="proj.overview">üìã Project Overview</h2>
            <p>A sophisticated enterprise-grade RAG (Retrieval-Augmented Generation) chatbot system featuring
                dual-stage retrieval, hybrid search capabilities, and hallucination verification. Designed for
                internal security requirements, the system works with local LLM inference servers (vLLM, Ollama)
                without external API calls, making it suitable for sensitive business applications.</p>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.problem">üéØ Problem Definition & Goals</h2>
            <ul class="feature-list">
                <li><strong>Problem:</strong> Enterprise chatbots often suffer from hallucinations and lack the ability
                    to use internal knowledge bases securely. Many solutions require external API calls,
                    creating data privacy concerns.</li>
                <li><strong>Goal 1:</strong> Build a fully local RAG system that can answer questions using
                    company-specific QnA pairs and Terms of Service documents.</li>
                <li><strong>Goal 2:</strong> Implement dual-stage retrieval that prioritizes curated answers
                    before searching complex documents.</li>
                <li><strong>Goal 3:</strong> Add hallucination verification to ensure all answers are grounded
                    in retrieved context.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.features">‚öôÔ∏è Key Features & Contributions</h2>
            <ul class="feature-list">
                <li><strong>Dual-Stage RAG Pipeline:</strong> First searches curated QnA database for direct matches,
                    then falls back to ToS document search for complex queries.</li>
                <li><strong>Hybrid Search:</strong> Combines vector search (E5 embeddings), rule-based matching,
                    and knowledge graph triplets for comprehensive retrieval.</li>
                <li><strong>Advanced Ranking:</strong> Two-stage ranking using Bi-Encoder (E5) for fast initial
                    retrieval
                    and Cross-Encoder (BGE-Reranker) for precise re-ranking.</li>
                <li><strong>Hallucination Verification:</strong> LLM-based verification step that checks if generated
                    answers are supported by retrieved context.</li>
                <li><strong>MCP Server Support:</strong> Model Context Protocol integration for Claude Desktop
                    compatibility.</li>
                <li><strong>Local LLM Ready:</strong> Works seamlessly with vLLM and Ollama via OpenAI-compatible APIs.
                </li>
            </ul>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.challenges">üîß Technical Challenges & Solutions</h2>
            <ul class="feature-list">
                <li><strong>Retrieval Quality:</strong> Simple vector search missed semantic matches.
                    Implemented hybrid approach combining dense, sparse, and knowledge graph retrieval.</li>
                <li><strong>Hallucination Detection:</strong> LLMs confidently generated incorrect information.
                    Added verification agent that cross-references answers with source documents.</li>
                <li><strong>Unknown Answer Handling:</strong> System needed to gracefully handle queries outside its
                    knowledge.
                    Implemented confidence scoring and explicit "I don't know" responses when appropriate.</li>
                <li><strong>Latency Optimization:</strong> Multiple retrieval stages added latency.
                    Implemented caching, parallel retrieval, and early termination for high-confidence matches.</li>
            </ul>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.results">üìà Results & Learnings</h2>
            <ul class="feature-list">
                <li><strong>Improved Accuracy:</strong> Dual-stage retrieval significantly improved answer relevance
                    compared to single-stage vector search.</li>
                <li><strong>Reduced Hallucinations:</strong> Verification step catches and prevents ~85% of
                    hallucinated responses before reaching users.</li>
                <li><strong>Security Compliance:</strong> Fully local deployment meets enterprise security requirements
                    with no external data transmission.</li>
                <li><strong>Key Learning:</strong> Gained deep expertise in production RAG systems, embedding models,
                    re-ranking strategies, and the critical importance of hallucination prevention in enterprise AI.
                </li>
            </ul>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.tech">üõ†Ô∏è Technologies</h2>
            <div class="tech-tags">
                <span class="tech-tag">Python</span>
                <span class="tech-tag">LangChain</span>
                <span class="tech-tag">vLLM</span>
                <span class="tech-tag">Ollama</span>
                <span class="tech-tag">E5</span>
                <span class="tech-tag">BGE-Reranker</span>
                <span class="tech-tag">MCP</span>
                <span class="tech-tag">Streamlit</span>
            </div>
        </section>

        <section class="project-section">
            <h2 data-i18n="proj.links">üîó Links</h2>
            <div class="project-links">
                <a href="https://github.com/junyeong-nero/tiny-chatbot-agents" target="_blank" class="project-link">
                    üíª GitHub Repository
                </a>
            </div>
        </section>
    </main>

    <script src="../theme.js"></script>
    <script src="../lang.js"></script>
</body>

</html>